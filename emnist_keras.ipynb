{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of emnist_keras.ipynb","version":"0.3.2","provenance":[{"file_id":"1PNSXsZzbIUbmKrgJ_Kfl9qzA5B_Kcf9m","timestamp":1557785496168}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LSImnGXqNftj","colab_type":"text"},"source":["Using mnsit_cnn.py architecture for training on emnist"]},{"cell_type":"code","metadata":{"id":"fRkNCJtjJFPj","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import datetime, os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ub3k-yDqIfew","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-kiBkxgIrT5","colab_type":"code","colab":{}},"source":["from scipy import io as sio\n","emnist = sio.loadmat(\"emnist-letters.mat\")\n","x_train = emnist[\"dataset\"]['train'][0,0]['images'][0,0]\n","#x_train = x_train.astype(np.float32)\n","\n","y_train = emnist[\"dataset\"]['train'][0,0]['labels'][0,0]\n","\n","x_test = emnist[\"dataset\"]['test'][0,0]['images'][0,0]\n","#x_test = x_test.astype(np.float32)\n","\n","y_test = emnist[\"dataset\"]['test'][0,0]['labels'][0,0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7x4CPh5UKb3S","colab_type":"code","colab":{}},"source":["x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","from sklearn.preprocessing import LabelBinarizer\n","lb = LabelBinarizer()\n","lb.fit([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26])\n","#lb.classes_array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26])\n","y_train = lb.transform(y_train)\n","y_test = lb.transform(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XY9az4sqIqA5","colab_type":"code","outputId":"bd2f6fbb-e827-4328-de37-98d245d15c9c","executionInfo":{"status":"ok","timestamp":1557785394139,"user_tz":420,"elapsed":396421,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":1088}},"source":["batch_size = 128\n","epochs = 30\n","\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Train on 124800 samples, validate on 20800 samples\n","Epoch 1/30\n","124800/124800 [==============================] - 14s 115us/step - loss: 0.7842 - acc: 0.7629 - val_loss: 0.3100 - val_acc: 0.9021\n","Epoch 2/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.4095 - acc: 0.8725 - val_loss: 0.2500 - val_acc: 0.9208\n","Epoch 3/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.3440 - acc: 0.8916 - val_loss: 0.2376 - val_acc: 0.9250\n","Epoch 4/30\n","124800/124800 [==============================] - 13s 103us/step - loss: 0.3102 - acc: 0.9018 - val_loss: 0.2188 - val_acc: 0.9291\n","Epoch 5/30\n","124800/124800 [==============================] - 13s 103us/step - loss: 0.2905 - acc: 0.9073 - val_loss: 0.2149 - val_acc: 0.9324\n","Epoch 6/30\n","124800/124800 [==============================] - 13s 105us/step - loss: 0.2716 - acc: 0.9124 - val_loss: 0.2100 - val_acc: 0.9318\n","Epoch 7/30\n","124800/124800 [==============================] - 13s 107us/step - loss: 0.2602 - acc: 0.9169 - val_loss: 0.2071 - val_acc: 0.9345\n","Epoch 8/30\n","124800/124800 [==============================] - 13s 103us/step - loss: 0.2526 - acc: 0.9193 - val_loss: 0.2060 - val_acc: 0.9353\n","Epoch 9/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2436 - acc: 0.9219 - val_loss: 0.2054 - val_acc: 0.9356\n","Epoch 10/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2385 - acc: 0.9230 - val_loss: 0.2065 - val_acc: 0.9377\n","Epoch 11/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2343 - acc: 0.9232 - val_loss: 0.1957 - val_acc: 0.9385\n","Epoch 12/30\n","124800/124800 [==============================] - 13s 105us/step - loss: 0.2313 - acc: 0.9254 - val_loss: 0.2002 - val_acc: 0.9366\n","Epoch 13/30\n","124800/124800 [==============================] - 13s 107us/step - loss: 0.2294 - acc: 0.9261 - val_loss: 0.1995 - val_acc: 0.9367\n","Epoch 14/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2238 - acc: 0.9275 - val_loss: 0.1998 - val_acc: 0.9383\n","Epoch 15/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2215 - acc: 0.9286 - val_loss: 0.2120 - val_acc: 0.9387\n","Epoch 16/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2195 - acc: 0.9298 - val_loss: 0.1960 - val_acc: 0.9379\n","Epoch 17/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2185 - acc: 0.9290 - val_loss: 0.2077 - val_acc: 0.9389\n","Epoch 18/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2144 - acc: 0.9308 - val_loss: 0.1995 - val_acc: 0.9375\n","Epoch 19/30\n","124800/124800 [==============================] - 14s 110us/step - loss: 0.2155 - acc: 0.9307 - val_loss: 0.2121 - val_acc: 0.9396\n","Epoch 20/30\n","124800/124800 [==============================] - 13s 105us/step - loss: 0.2144 - acc: 0.9313 - val_loss: 0.2044 - val_acc: 0.9392\n","Epoch 21/30\n","124800/124800 [==============================] - 13s 107us/step - loss: 0.2144 - acc: 0.9312 - val_loss: 0.2018 - val_acc: 0.9390\n","Epoch 22/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2100 - acc: 0.9322 - val_loss: 0.2185 - val_acc: 0.9387\n","Epoch 23/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2125 - acc: 0.9319 - val_loss: 0.1942 - val_acc: 0.9386\n","Epoch 24/30\n","124800/124800 [==============================] - 13s 105us/step - loss: 0.2088 - acc: 0.9332 - val_loss: 0.2111 - val_acc: 0.9392\n","Epoch 25/30\n","124800/124800 [==============================] - 14s 108us/step - loss: 0.2066 - acc: 0.9330 - val_loss: 0.2009 - val_acc: 0.9392\n","Epoch 26/30\n","124800/124800 [==============================] - 13s 104us/step - loss: 0.2060 - acc: 0.9340 - val_loss: 0.2002 - val_acc: 0.9390\n","Epoch 27/30\n","124800/124800 [==============================] - 13s 105us/step - loss: 0.2069 - acc: 0.9341 - val_loss: 0.1982 - val_acc: 0.9395\n","Epoch 28/30\n","124800/124800 [==============================] - 13s 105us/step - loss: 0.2025 - acc: 0.9348 - val_loss: 0.2201 - val_acc: 0.9393\n","Epoch 29/30\n","124800/124800 [==============================] - 13s 106us/step - loss: 0.2063 - acc: 0.9333 - val_loss: 0.1922 - val_acc: 0.9384\n","Epoch 30/30\n","124800/124800 [==============================] - 13s 106us/step - loss: 0.2026 - acc: 0.9343 - val_loss: 0.1979 - val_acc: 0.9384\n","Test loss: 0.19794438956135238\n","Test accuracy: 0.9384134615384615\n"],"name":"stdout"}]}]}