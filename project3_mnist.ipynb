{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project3_mnist.ipynb","version":"0.3.2","provenance":[{"file_id":"1LT-57zvDo0PsMz6mnq0YnvZEb5iZMmWj","timestamp":1557707464944}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"83R4HzrysgVn","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","import numpy as np\n","from tensorflow.keras import layers\n","from tensorflow import keras \n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsRltKhTtwM5","colab_type":"code","outputId":"c5ecb01d-b0dc-45e6-f707-af3123900269","executionInfo":{"status":"ok","timestamp":1557622795958,"user_tz":420,"elapsed":184100,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":1275}},"source":["from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import RMSprop\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 20\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 784)\n","x_test = x_test.reshape(10000, 784)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(784,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","60000 train samples\n","10000 test samples\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 512)               401920    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 669,706\n","Trainable params: 669,706\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 10s 158us/step - loss: 0.2469 - acc: 0.9243 - val_loss: 0.1167 - val_acc: 0.9655\n","Epoch 2/20\n","60000/60000 [==============================] - 9s 145us/step - loss: 0.1030 - acc: 0.9684 - val_loss: 0.0886 - val_acc: 0.9727\n","Epoch 3/20\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0752 - acc: 0.9772 - val_loss: 0.0789 - val_acc: 0.9773\n","Epoch 4/20\n","60000/60000 [==============================] - 9s 145us/step - loss: 0.0593 - acc: 0.9821 - val_loss: 0.0810 - val_acc: 0.9790\n","Epoch 5/20\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0522 - acc: 0.9847 - val_loss: 0.0762 - val_acc: 0.9792\n","Epoch 6/20\n","60000/60000 [==============================] - 9s 145us/step - loss: 0.0421 - acc: 0.9874 - val_loss: 0.0803 - val_acc: 0.9813\n","Epoch 7/20\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0733 - val_acc: 0.9809\n","Epoch 8/20\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0349 - acc: 0.9896 - val_loss: 0.0803 - val_acc: 0.9826\n","Epoch 9/20\n","60000/60000 [==============================] - 9s 148us/step - loss: 0.0301 - acc: 0.9910 - val_loss: 0.0903 - val_acc: 0.9809\n","Epoch 10/20\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0296 - acc: 0.9915 - val_loss: 0.0931 - val_acc: 0.9828\n","Epoch 11/20\n","60000/60000 [==============================] - 9s 143us/step - loss: 0.0265 - acc: 0.9925 - val_loss: 0.0915 - val_acc: 0.9819\n","Epoch 12/20\n","60000/60000 [==============================] - 9s 145us/step - loss: 0.0255 - acc: 0.9924 - val_loss: 0.0989 - val_acc: 0.9820\n","Epoch 13/20\n","60000/60000 [==============================] - 9s 143us/step - loss: 0.0233 - acc: 0.9934 - val_loss: 0.0930 - val_acc: 0.9843\n","Epoch 14/20\n","60000/60000 [==============================] - 9s 142us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.1091 - val_acc: 0.9808\n","Epoch 15/20\n","60000/60000 [==============================] - 9s 144us/step - loss: 0.0244 - acc: 0.9933 - val_loss: 0.1033 - val_acc: 0.9818\n","Epoch 16/20\n","60000/60000 [==============================] - 9s 142us/step - loss: 0.0197 - acc: 0.9943 - val_loss: 0.1060 - val_acc: 0.9840\n","Epoch 17/20\n","60000/60000 [==============================] - 9s 145us/step - loss: 0.0206 - acc: 0.9944 - val_loss: 0.1546 - val_acc: 0.9770\n","Epoch 18/20\n","60000/60000 [==============================] - 9s 146us/step - loss: 0.0199 - acc: 0.9949 - val_loss: 0.1128 - val_acc: 0.9825\n","Epoch 19/20\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0216 - acc: 0.9948 - val_loss: 0.1136 - val_acc: 0.9829\n","Epoch 20/20\n","60000/60000 [==============================] - 9s 149us/step - loss: 0.0165 - acc: 0.9956 - val_loss: 0.1211 - val_acc: 0.9827\n","Test loss: 0.12111109673878896\n","Test accuracy: 0.9827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qct6Z-TqvAz0","colab_type":"code","outputId":"053b33ab-c705-47ea-a3de-db5b2c2c59d8","executionInfo":{"status":"ok","timestamp":1557624743407,"user_tz":420,"elapsed":1667979,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","batch_size = 128\n","num_classes = 10\n","epochs = 12\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/12\n","60000/60000 [==============================] - 163s 3ms/step - loss: 0.2571 - acc: 0.9206 - val_loss: 0.0564 - val_acc: 0.9820\n","Epoch 2/12\n","60000/60000 [==============================] - 160s 3ms/step - loss: 0.0892 - acc: 0.9737 - val_loss: 0.0420 - val_acc: 0.9857\n","Epoch 3/12\n","60000/60000 [==============================] - 161s 3ms/step - loss: 0.0656 - acc: 0.9808 - val_loss: 0.0344 - val_acc: 0.9893\n","Epoch 4/12\n","60000/60000 [==============================] - 162s 3ms/step - loss: 0.0522 - acc: 0.9839 - val_loss: 0.0329 - val_acc: 0.9893\n","Epoch 5/12\n","60000/60000 [==============================] - 162s 3ms/step - loss: 0.0462 - acc: 0.9856 - val_loss: 0.0339 - val_acc: 0.9887\n","Epoch 6/12\n","60000/60000 [==============================] - 163s 3ms/step - loss: 0.0410 - acc: 0.9876 - val_loss: 0.0300 - val_acc: 0.9901\n","Epoch 7/12\n","60000/60000 [==============================] - 163s 3ms/step - loss: 0.0370 - acc: 0.9886 - val_loss: 0.0289 - val_acc: 0.9912\n","Epoch 8/12\n","60000/60000 [==============================] - 162s 3ms/step - loss: 0.0333 - acc: 0.9891 - val_loss: 0.0289 - val_acc: 0.9912\n","Epoch 9/12\n","60000/60000 [==============================] - 162s 3ms/step - loss: 0.0292 - acc: 0.9908 - val_loss: 0.0273 - val_acc: 0.9916\n","Epoch 10/12\n","60000/60000 [==============================] - 162s 3ms/step - loss: 0.0297 - acc: 0.9907 - val_loss: 0.0270 - val_acc: 0.9917\n","Epoch 11/12\n","60000/60000 [==============================] - 160s 3ms/step - loss: 0.0281 - acc: 0.9911 - val_loss: 0.0284 - val_acc: 0.9920\n","Epoch 12/12\n","60000/60000 [==============================] - 159s 3ms/step - loss: 0.0250 - acc: 0.9919 - val_loss: 0.0258 - val_acc: 0.9925\n","Test loss: 0.025808923006483794\n","Test accuracy: 0.9925\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B5jAJjXztant","colab_type":"code","outputId":"3a9d72e9-86f4-4a4f-931d-1793ba79c52a","executionInfo":{"status":"ok","timestamp":1557628842458,"user_tz":420,"elapsed":581,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n","print(X_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x5hdb914xQK6","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n","training_data = (X_train, y_train)\n","test_data = (X_test, y_test)\n","validation_data = (X_val, y_val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4Zb3tVn2GkJ","colab_type":"code","outputId":"2fa10d0f-ee8b-44e0-e152-4b8f39b3ccc5","executionInfo":{"status":"ok","timestamp":1557633234334,"user_tz":420,"elapsed":4380680,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":2550}},"source":["\n","from network3 import Network, ReLU\n","from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n","training_data, validation_data, test_data = network3.load_data_shared()\n","mini_batch_size = 10\n","net = Network([\n","        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n","                      filter_shape=(20, 1, 5, 5), \n","                      poolsize=(2, 2), \n","                      activation_fn=ReLU),\n","        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n","                      filter_shape=(40, 20, 5, 5), \n","                      poolsize=(2, 2), \n","                      activation_fn=ReLU),\n","        FullyConnectedLayer(\n","            n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n","        FullyConnectedLayer(\n","            n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n","        SoftmaxLayer(n_in=1000, n_out=10, p_dropout=0.5)], \n","        mini_batch_size)\n","net.SGD(training_data, 20, mini_batch_size, 0.03, \n","            test_data, test_data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/theano/tensor/nnet/conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n","  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n"],"name":"stderr"},{"output_type":"stream","text":["Training mini-batch number 0\n","Training mini-batch number 1000\n","Training mini-batch number 2000\n","Training mini-batch number 3000\n","Training mini-batch number 4000\n","Epoch 0: validation accuracy 95.79%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 95.79%\n","Training mini-batch number 5000\n","Training mini-batch number 6000\n","Training mini-batch number 7000\n","Training mini-batch number 8000\n","Training mini-batch number 9000\n","Epoch 1: validation accuracy 97.66%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 97.66%\n","Training mini-batch number 10000\n","Training mini-batch number 11000\n","Training mini-batch number 12000\n","Training mini-batch number 13000\n","Training mini-batch number 14000\n","Epoch 2: validation accuracy 97.92%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 97.92%\n","Training mini-batch number 15000\n","Training mini-batch number 16000\n","Training mini-batch number 17000\n","Training mini-batch number 18000\n","Training mini-batch number 19000\n","Epoch 3: validation accuracy 98.67%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 98.67%\n","Training mini-batch number 20000\n","Training mini-batch number 21000\n","Training mini-batch number 22000\n","Training mini-batch number 23000\n","Training mini-batch number 24000\n","Epoch 4: validation accuracy 98.66%\n","Training mini-batch number 25000\n","Training mini-batch number 26000\n","Training mini-batch number 27000\n","Training mini-batch number 28000\n","Training mini-batch number 29000\n","Epoch 5: validation accuracy 98.72%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 98.72%\n","Training mini-batch number 30000\n","Training mini-batch number 31000\n","Training mini-batch number 32000\n","Training mini-batch number 33000\n","Training mini-batch number 34000\n","Epoch 6: validation accuracy 98.80%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 98.80%\n","Training mini-batch number 35000\n","Training mini-batch number 36000\n","Training mini-batch number 37000\n","Training mini-batch number 38000\n","Training mini-batch number 39000\n","Epoch 7: validation accuracy 99.12%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.12%\n","Training mini-batch number 40000\n","Training mini-batch number 41000\n","Training mini-batch number 42000\n","Training mini-batch number 43000\n","Training mini-batch number 44000\n","Epoch 8: validation accuracy 99.02%\n","Training mini-batch number 45000\n","Training mini-batch number 46000\n","Training mini-batch number 47000\n","Training mini-batch number 48000\n","Training mini-batch number 49000\n","Epoch 9: validation accuracy 99.19%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.19%\n","Training mini-batch number 50000\n","Training mini-batch number 51000\n","Training mini-batch number 52000\n","Training mini-batch number 53000\n","Training mini-batch number 54000\n","Epoch 10: validation accuracy 99.19%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.19%\n","Training mini-batch number 55000\n","Training mini-batch number 56000\n","Training mini-batch number 57000\n","Training mini-batch number 58000\n","Training mini-batch number 59000\n","Epoch 11: validation accuracy 99.23%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.23%\n","Training mini-batch number 60000\n","Training mini-batch number 61000\n","Training mini-batch number 62000\n","Training mini-batch number 63000\n","Training mini-batch number 64000\n","Epoch 12: validation accuracy 99.33%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.33%\n","Training mini-batch number 65000\n","Training mini-batch number 66000\n","Training mini-batch number 67000\n","Training mini-batch number 68000\n","Training mini-batch number 69000\n","Epoch 13: validation accuracy 99.27%\n","Training mini-batch number 70000\n","Training mini-batch number 71000\n","Training mini-batch number 72000\n","Training mini-batch number 73000\n","Training mini-batch number 74000\n","Epoch 14: validation accuracy 99.35%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.35%\n","Training mini-batch number 75000\n","Training mini-batch number 76000\n","Training mini-batch number 77000\n","Training mini-batch number 78000\n","Training mini-batch number 79000\n","Epoch 15: validation accuracy 99.34%\n","Training mini-batch number 80000\n","Training mini-batch number 81000\n","Training mini-batch number 82000\n","Training mini-batch number 83000\n","Training mini-batch number 84000\n","Epoch 16: validation accuracy 99.31%\n","Training mini-batch number 85000\n","Training mini-batch number 86000\n","Training mini-batch number 87000\n","Training mini-batch number 88000\n","Training mini-batch number 89000\n","Epoch 17: validation accuracy 99.32%\n","Training mini-batch number 90000\n","Training mini-batch number 91000\n","Training mini-batch number 92000\n","Training mini-batch number 93000\n","Training mini-batch number 94000\n","Epoch 18: validation accuracy 99.28%\n","Training mini-batch number 95000\n","Training mini-batch number 96000\n","Training mini-batch number 97000\n","Training mini-batch number 98000\n","Training mini-batch number 99000\n","Epoch 19: validation accuracy 99.31%\n","Finished training network.\n","Best validation accuracy of 99.35% obtained at iteration 74999\n","Corresponding test accuracy of 99.35%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bgia-P41TU95","colab_type":"code","outputId":"526ad212-f23b-4102-e671-38573dc42d4c","executionInfo":{"status":"ok","timestamp":1557635474757,"user_tz":420,"elapsed":117871,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["\"\"\"expand_mnist.py\n","~~~~~~~~~~~~~~~~~~\n","\n","Take the 50,000 MNIST training images, and create an expanded set of\n","250,000 images, by displacing each training image up, down, left and\n","right, by one pixel.  Save the resulting file to\n","../data/mnist_expanded.pkl.gz.\n","\n","Note that this program is memory intensive, and may not run on small\n","systems.\n","\n","\"\"\"\n","\n","from __future__ import print_function\n","\n","#### Libraries\n","\n","# Standard library\n","import pickle\n","import gzip\n","import os.path\n","import random\n","\n","# Third-party libraries\n","import numpy as np\n","\n","print(\"Expanding the MNIST training set\")\n","\n","if os.path.exists(\"mnist_expanded.pkl.gz\"):\n","    print(\"The expanded training set already exists.  Exiting.\")\n","else:\n","    f = gzip.open(\"mnist.pkl.gz\", 'rb')\n","    training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n","    f.close()\n","    expanded_training_pairs = []\n","    j = 0 # counter\n","    for x, y in zip(training_data[0], training_data[1]):\n","        expanded_training_pairs.append((x, y))\n","        image = np.reshape(x, (-1, 28))\n","        j += 1\n","        if j % 1000 == 0: print(\"Expanding image number\", j)\n","        # iterate over data telling us the details of how to\n","        # do the displacement\n","        for d, axis, index_position, index in [\n","                (1,  0, \"first\", 0),\n","                (-1, 0, \"first\", 27),\n","                (1,  1, \"last\",  0),\n","                (-1, 1, \"last\",  27)]:\n","            new_img = np.roll(image, d, axis)\n","            if index_position == \"first\": \n","                new_img[index, :] = np.zeros(28)\n","            else: \n","                new_img[:, index] = np.zeros(28)\n","            expanded_training_pairs.append((np.reshape(new_img, 784), y))\n","    random.shuffle(expanded_training_pairs)\n","    expanded_training_data = [list(d) for d in zip(*expanded_training_pairs)]\n","    print(\"Saving expanded data. This may take a few minutes.\")\n","    f = gzip.open(\"mnist_expanded.pkl.gz\", \"w\")\n","    pickle.dump((expanded_training_data, validation_data, test_data), f)\n","    f.close()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Expanding the MNIST training set\n","Expanding image number 1000\n","Expanding image number 2000\n","Expanding image number 3000\n","Expanding image number 4000\n","Expanding image number 5000\n","Expanding image number 6000\n","Expanding image number 7000\n","Expanding image number 8000\n","Expanding image number 9000\n","Expanding image number 10000\n","Expanding image number 11000\n","Expanding image number 12000\n","Expanding image number 13000\n","Expanding image number 14000\n","Expanding image number 15000\n","Expanding image number 16000\n","Expanding image number 17000\n","Expanding image number 18000\n","Expanding image number 19000\n","Expanding image number 20000\n","Expanding image number 21000\n","Expanding image number 22000\n","Expanding image number 23000\n","Expanding image number 24000\n","Expanding image number 25000\n","Expanding image number 26000\n","Expanding image number 27000\n","Expanding image number 28000\n","Expanding image number 29000\n","Expanding image number 30000\n","Expanding image number 31000\n","Expanding image number 32000\n","Expanding image number 33000\n","Expanding image number 34000\n","Expanding image number 35000\n","Expanding image number 36000\n","Expanding image number 37000\n","Expanding image number 38000\n","Expanding image number 39000\n","Expanding image number 40000\n","Expanding image number 41000\n","Expanding image number 42000\n","Expanding image number 43000\n","Expanding image number 44000\n","Expanding image number 45000\n","Expanding image number 46000\n","Expanding image number 47000\n","Expanding image number 48000\n","Expanding image number 49000\n","Expanding image number 50000\n","Saving expanded data. This may take a few minutes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MPd5op5VOxg2","colab_type":"code","outputId":"b70c1e72-8690-42cd-be1c-afc442f5b085","executionInfo":{"status":"ok","timestamp":1557706724401,"user_tz":420,"elapsed":16396599,"user":{"displayName":"Akhileshwar Bomma","photoUrl":"","userId":"05232143550238454681"}},"colab":{"base_uri":"https://localhost:8080/","height":9268}},"source":["import network3\n","from network3 import Network, ReLU\n","from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n","expanded_training_data, validation_data, test_data = network3.load_data_shared(\"mnist_expanded.pkl.gz\")\n","mini_batch_size = 10\n","net = Network([\n","        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n","                      filter_shape=(20, 1, 5, 5), \n","                      poolsize=(2, 2), \n","                      activation_fn=ReLU),\n","        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n","                      filter_shape=(40, 20, 5, 5), \n","                      poolsize=(2, 2), \n","                      activation_fn=ReLU),\n","        FullyConnectedLayer(\n","            n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n","        FullyConnectedLayer(\n","            n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n","        SoftmaxLayer(n_in=1000, n_out=10, p_dropout=0.5)], \n","        mini_batch_size)\n","net.SGD(expanded_training_data, 20, mini_batch_size, 0.03, \n","            validation_data, test_data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/theano/tensor/nnet/conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n","  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n"],"name":"stderr"},{"output_type":"stream","text":["Training mini-batch number 0\n","Training mini-batch number 1000\n","Training mini-batch number 2000\n","Training mini-batch number 3000\n","Training mini-batch number 4000\n","Training mini-batch number 5000\n","Training mini-batch number 6000\n","Training mini-batch number 7000\n","Training mini-batch number 8000\n","Training mini-batch number 9000\n","Training mini-batch number 10000\n","Training mini-batch number 11000\n","Training mini-batch number 12000\n","Training mini-batch number 13000\n","Training mini-batch number 14000\n","Training mini-batch number 15000\n","Training mini-batch number 16000\n","Training mini-batch number 17000\n","Training mini-batch number 18000\n","Training mini-batch number 19000\n","Training mini-batch number 20000\n","Training mini-batch number 21000\n","Training mini-batch number 22000\n","Training mini-batch number 23000\n","Training mini-batch number 24000\n","Epoch 0: validation accuracy 98.60%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 98.87%\n","Training mini-batch number 25000\n","Training mini-batch number 26000\n","Training mini-batch number 27000\n","Training mini-batch number 28000\n","Training mini-batch number 29000\n","Training mini-batch number 30000\n","Training mini-batch number 31000\n","Training mini-batch number 32000\n","Training mini-batch number 33000\n","Training mini-batch number 34000\n","Training mini-batch number 35000\n","Training mini-batch number 36000\n","Training mini-batch number 37000\n","Training mini-batch number 38000\n","Training mini-batch number 39000\n","Training mini-batch number 40000\n","Training mini-batch number 41000\n","Training mini-batch number 42000\n","Training mini-batch number 43000\n","Training mini-batch number 44000\n","Training mini-batch number 45000\n","Training mini-batch number 46000\n","Training mini-batch number 47000\n","Training mini-batch number 48000\n","Training mini-batch number 49000\n","Epoch 1: validation accuracy 99.05%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.24%\n","Training mini-batch number 50000\n","Training mini-batch number 51000\n","Training mini-batch number 52000\n","Training mini-batch number 53000\n","Training mini-batch number 54000\n","Training mini-batch number 55000\n","Training mini-batch number 56000\n","Training mini-batch number 57000\n","Training mini-batch number 58000\n","Training mini-batch number 59000\n","Training mini-batch number 60000\n","Training mini-batch number 61000\n","Training mini-batch number 62000\n","Training mini-batch number 63000\n","Training mini-batch number 64000\n","Training mini-batch number 65000\n","Training mini-batch number 66000\n","Training mini-batch number 67000\n","Training mini-batch number 68000\n","Training mini-batch number 69000\n","Training mini-batch number 70000\n","Training mini-batch number 71000\n","Training mini-batch number 72000\n","Training mini-batch number 73000\n","Training mini-batch number 74000\n","Epoch 2: validation accuracy 99.20%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.37%\n","Training mini-batch number 75000\n","Training mini-batch number 76000\n","Training mini-batch number 77000\n","Training mini-batch number 78000\n","Training mini-batch number 79000\n","Training mini-batch number 80000\n","Training mini-batch number 81000\n","Training mini-batch number 82000\n","Training mini-batch number 83000\n","Training mini-batch number 84000\n","Training mini-batch number 85000\n","Training mini-batch number 86000\n","Training mini-batch number 87000\n","Training mini-batch number 88000\n","Training mini-batch number 89000\n","Training mini-batch number 90000\n","Training mini-batch number 91000\n","Training mini-batch number 92000\n","Training mini-batch number 93000\n","Training mini-batch number 94000\n","Training mini-batch number 95000\n","Training mini-batch number 96000\n","Training mini-batch number 97000\n","Training mini-batch number 98000\n","Training mini-batch number 99000\n","Epoch 3: validation accuracy 99.17%\n","Training mini-batch number 100000\n","Training mini-batch number 101000\n","Training mini-batch number 102000\n","Training mini-batch number 103000\n","Training mini-batch number 104000\n","Training mini-batch number 105000\n","Training mini-batch number 106000\n","Training mini-batch number 107000\n","Training mini-batch number 108000\n","Training mini-batch number 109000\n","Training mini-batch number 110000\n","Training mini-batch number 111000\n","Training mini-batch number 112000\n","Training mini-batch number 113000\n","Training mini-batch number 114000\n","Training mini-batch number 115000\n","Training mini-batch number 116000\n","Training mini-batch number 117000\n","Training mini-batch number 118000\n","Training mini-batch number 119000\n","Training mini-batch number 120000\n","Training mini-batch number 121000\n","Training mini-batch number 122000\n","Training mini-batch number 123000\n","Training mini-batch number 124000\n","Epoch 4: validation accuracy 99.36%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.40%\n","Training mini-batch number 125000\n","Training mini-batch number 126000\n","Training mini-batch number 127000\n","Training mini-batch number 128000\n","Training mini-batch number 129000\n","Training mini-batch number 130000\n","Training mini-batch number 131000\n","Training mini-batch number 132000\n","Training mini-batch number 133000\n","Training mini-batch number 134000\n","Training mini-batch number 135000\n","Training mini-batch number 136000\n","Training mini-batch number 137000\n","Training mini-batch number 138000\n","Training mini-batch number 139000\n","Training mini-batch number 140000\n","Training mini-batch number 141000\n","Training mini-batch number 142000\n","Training mini-batch number 143000\n","Training mini-batch number 144000\n","Training mini-batch number 145000\n","Training mini-batch number 146000\n","Training mini-batch number 147000\n","Training mini-batch number 148000\n","Training mini-batch number 149000\n","Epoch 5: validation accuracy 99.39%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.46%\n","Training mini-batch number 150000\n","Training mini-batch number 151000\n","Training mini-batch number 152000\n","Training mini-batch number 153000\n","Training mini-batch number 154000\n","Training mini-batch number 155000\n","Training mini-batch number 156000\n","Training mini-batch number 157000\n","Training mini-batch number 158000\n","Training mini-batch number 159000\n","Training mini-batch number 160000\n","Training mini-batch number 161000\n","Training mini-batch number 162000\n","Training mini-batch number 163000\n","Training mini-batch number 164000\n","Training mini-batch number 165000\n","Training mini-batch number 166000\n","Training mini-batch number 167000\n","Training mini-batch number 168000\n","Training mini-batch number 169000\n","Training mini-batch number 170000\n","Training mini-batch number 171000\n","Training mini-batch number 172000\n","Training mini-batch number 173000\n","Training mini-batch number 174000\n","Epoch 6: validation accuracy 99.38%\n","Training mini-batch number 175000\n","Training mini-batch number 176000\n","Training mini-batch number 177000\n","Training mini-batch number 178000\n","Training mini-batch number 179000\n","Training mini-batch number 180000\n","Training mini-batch number 181000\n","Training mini-batch number 182000\n","Training mini-batch number 183000\n","Training mini-batch number 184000\n","Training mini-batch number 185000\n","Training mini-batch number 186000\n","Training mini-batch number 187000\n","Training mini-batch number 188000\n","Training mini-batch number 189000\n","Training mini-batch number 190000\n","Training mini-batch number 191000\n","Training mini-batch number 192000\n","Training mini-batch number 193000\n","Training mini-batch number 194000\n","Training mini-batch number 195000\n","Training mini-batch number 196000\n","Training mini-batch number 197000\n","Training mini-batch number 198000\n","Training mini-batch number 199000\n","Epoch 7: validation accuracy 99.43%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.61%\n","Training mini-batch number 200000\n","Training mini-batch number 201000\n","Training mini-batch number 202000\n","Training mini-batch number 203000\n","Training mini-batch number 204000\n","Training mini-batch number 205000\n","Training mini-batch number 206000\n","Training mini-batch number 207000\n","Training mini-batch number 208000\n","Training mini-batch number 209000\n","Training mini-batch number 210000\n","Training mini-batch number 211000\n","Training mini-batch number 212000\n","Training mini-batch number 213000\n","Training mini-batch number 214000\n","Training mini-batch number 215000\n","Training mini-batch number 216000\n","Training mini-batch number 217000\n","Training mini-batch number 218000\n","Training mini-batch number 219000\n","Training mini-batch number 220000\n","Training mini-batch number 221000\n","Training mini-batch number 222000\n","Training mini-batch number 223000\n","Training mini-batch number 224000\n","Epoch 8: validation accuracy 99.43%\n","Training mini-batch number 225000\n","Training mini-batch number 226000\n","Training mini-batch number 227000\n","Training mini-batch number 228000\n","Training mini-batch number 229000\n","Training mini-batch number 230000\n","Training mini-batch number 231000\n","Training mini-batch number 232000\n","Training mini-batch number 233000\n","Training mini-batch number 234000\n","Training mini-batch number 235000\n","Training mini-batch number 236000\n","Training mini-batch number 237000\n","Training mini-batch number 238000\n","Training mini-batch number 239000\n","Training mini-batch number 240000\n","Training mini-batch number 241000\n","Training mini-batch number 242000\n","Training mini-batch number 243000\n","Training mini-batch number 244000\n","Training mini-batch number 245000\n","Training mini-batch number 246000\n","Training mini-batch number 247000\n","Training mini-batch number 248000\n","Training mini-batch number 249000\n","Epoch 9: validation accuracy 99.46%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.53%\n","Training mini-batch number 250000\n","Training mini-batch number 251000\n","Training mini-batch number 252000\n","Training mini-batch number 253000\n","Training mini-batch number 254000\n","Training mini-batch number 255000\n","Training mini-batch number 256000\n","Training mini-batch number 257000\n","Training mini-batch number 258000\n","Training mini-batch number 259000\n","Training mini-batch number 260000\n","Training mini-batch number 261000\n","Training mini-batch number 262000\n","Training mini-batch number 263000\n","Training mini-batch number 264000\n","Training mini-batch number 265000\n","Training mini-batch number 266000\n","Training mini-batch number 267000\n","Training mini-batch number 268000\n","Training mini-batch number 269000\n","Training mini-batch number 270000\n","Training mini-batch number 271000\n","Training mini-batch number 272000\n","Training mini-batch number 273000\n","Training mini-batch number 274000\n","Epoch 10: validation accuracy 99.41%\n","Training mini-batch number 275000\n","Training mini-batch number 276000\n","Training mini-batch number 277000\n","Training mini-batch number 278000\n","Training mini-batch number 279000\n","Training mini-batch number 280000\n","Training mini-batch number 281000\n","Training mini-batch number 282000\n","Training mini-batch number 283000\n","Training mini-batch number 284000\n","Training mini-batch number 285000\n","Training mini-batch number 286000\n","Training mini-batch number 287000\n","Training mini-batch number 288000\n","Training mini-batch number 289000\n","Training mini-batch number 290000\n","Training mini-batch number 291000\n","Training mini-batch number 292000\n","Training mini-batch number 293000\n","Training mini-batch number 294000\n","Training mini-batch number 295000\n","Training mini-batch number 296000\n","Training mini-batch number 297000\n","Training mini-batch number 298000\n","Training mini-batch number 299000\n","Epoch 11: validation accuracy 99.48%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.56%\n","Training mini-batch number 300000\n","Training mini-batch number 301000\n","Training mini-batch number 302000\n","Training mini-batch number 303000\n","Training mini-batch number 304000\n","Training mini-batch number 305000\n","Training mini-batch number 306000\n","Training mini-batch number 307000\n","Training mini-batch number 308000\n","Training mini-batch number 309000\n","Training mini-batch number 310000\n","Training mini-batch number 311000\n","Training mini-batch number 312000\n","Training mini-batch number 313000\n","Training mini-batch number 314000\n","Training mini-batch number 315000\n","Training mini-batch number 316000\n","Training mini-batch number 317000\n","Training mini-batch number 318000\n","Training mini-batch number 319000\n","Training mini-batch number 320000\n","Training mini-batch number 321000\n","Training mini-batch number 322000\n","Training mini-batch number 323000\n","Training mini-batch number 324000\n","Epoch 12: validation accuracy 99.47%\n","Training mini-batch number 325000\n","Training mini-batch number 326000\n","Training mini-batch number 327000\n","Training mini-batch number 328000\n","Training mini-batch number 329000\n","Training mini-batch number 330000\n","Training mini-batch number 331000\n","Training mini-batch number 332000\n","Training mini-batch number 333000\n","Training mini-batch number 334000\n","Training mini-batch number 335000\n","Training mini-batch number 336000\n","Training mini-batch number 337000\n","Training mini-batch number 338000\n","Training mini-batch number 339000\n","Training mini-batch number 340000\n","Training mini-batch number 341000\n","Training mini-batch number 342000\n","Training mini-batch number 343000\n","Training mini-batch number 344000\n","Training mini-batch number 345000\n","Training mini-batch number 346000\n","Training mini-batch number 347000\n","Training mini-batch number 348000\n","Training mini-batch number 349000\n","Epoch 13: validation accuracy 99.42%\n","Training mini-batch number 350000\n","Training mini-batch number 351000\n","Training mini-batch number 352000\n","Training mini-batch number 353000\n","Training mini-batch number 354000\n","Training mini-batch number 355000\n","Training mini-batch number 356000\n","Training mini-batch number 357000\n","Training mini-batch number 358000\n","Training mini-batch number 359000\n","Training mini-batch number 360000\n","Training mini-batch number 361000\n","Training mini-batch number 362000\n","Training mini-batch number 363000\n","Training mini-batch number 364000\n","Training mini-batch number 365000\n","Training mini-batch number 366000\n","Training mini-batch number 367000\n","Training mini-batch number 368000\n","Training mini-batch number 369000\n","Training mini-batch number 370000\n","Training mini-batch number 371000\n","Training mini-batch number 372000\n","Training mini-batch number 373000\n","Training mini-batch number 374000\n","Epoch 14: validation accuracy 99.44%\n","Training mini-batch number 375000\n","Training mini-batch number 376000\n","Training mini-batch number 377000\n","Training mini-batch number 378000\n","Training mini-batch number 379000\n","Training mini-batch number 380000\n","Training mini-batch number 381000\n","Training mini-batch number 382000\n","Training mini-batch number 383000\n","Training mini-batch number 384000\n","Training mini-batch number 385000\n","Training mini-batch number 386000\n","Training mini-batch number 387000\n","Training mini-batch number 388000\n","Training mini-batch number 389000\n","Training mini-batch number 390000\n","Training mini-batch number 391000\n","Training mini-batch number 392000\n","Training mini-batch number 393000\n","Training mini-batch number 394000\n","Training mini-batch number 395000\n","Training mini-batch number 396000\n","Training mini-batch number 397000\n","Training mini-batch number 398000\n","Training mini-batch number 399000\n","Epoch 15: validation accuracy 99.44%\n","Training mini-batch number 400000\n","Training mini-batch number 401000\n","Training mini-batch number 402000\n","Training mini-batch number 403000\n","Training mini-batch number 404000\n","Training mini-batch number 405000\n","Training mini-batch number 406000\n","Training mini-batch number 407000\n","Training mini-batch number 408000\n","Training mini-batch number 409000\n","Training mini-batch number 410000\n","Training mini-batch number 411000\n","Training mini-batch number 412000\n","Training mini-batch number 413000\n","Training mini-batch number 414000\n","Training mini-batch number 415000\n","Training mini-batch number 416000\n","Training mini-batch number 417000\n","Training mini-batch number 418000\n","Training mini-batch number 419000\n","Training mini-batch number 420000\n","Training mini-batch number 421000\n","Training mini-batch number 422000\n","Training mini-batch number 423000\n","Training mini-batch number 424000\n","Epoch 16: validation accuracy 99.46%\n","Training mini-batch number 425000\n","Training mini-batch number 426000\n","Training mini-batch number 427000\n","Training mini-batch number 428000\n","Training mini-batch number 429000\n","Training mini-batch number 430000\n","Training mini-batch number 431000\n","Training mini-batch number 432000\n","Training mini-batch number 433000\n","Training mini-batch number 434000\n","Training mini-batch number 435000\n","Training mini-batch number 436000\n","Training mini-batch number 437000\n","Training mini-batch number 438000\n","Training mini-batch number 439000\n","Training mini-batch number 440000\n","Training mini-batch number 441000\n","Training mini-batch number 442000\n","Training mini-batch number 443000\n","Training mini-batch number 444000\n","Training mini-batch number 445000\n","Training mini-batch number 446000\n","Training mini-batch number 447000\n","Training mini-batch number 448000\n","Training mini-batch number 449000\n","Epoch 17: validation accuracy 99.47%\n","Training mini-batch number 450000\n","Training mini-batch number 451000\n","Training mini-batch number 452000\n","Training mini-batch number 453000\n","Training mini-batch number 454000\n","Training mini-batch number 455000\n","Training mini-batch number 456000\n","Training mini-batch number 457000\n","Training mini-batch number 458000\n","Training mini-batch number 459000\n","Training mini-batch number 460000\n","Training mini-batch number 461000\n","Training mini-batch number 462000\n","Training mini-batch number 463000\n","Training mini-batch number 464000\n","Training mini-batch number 465000\n","Training mini-batch number 466000\n","Training mini-batch number 467000\n","Training mini-batch number 468000\n","Training mini-batch number 469000\n","Training mini-batch number 470000\n","Training mini-batch number 471000\n","Training mini-batch number 472000\n","Training mini-batch number 473000\n","Training mini-batch number 474000\n","Epoch 18: validation accuracy 99.61%\n","This is the best validation accuracy to date.\n","The corresponding test accuracy is 99.58%\n","Training mini-batch number 475000\n","Training mini-batch number 476000\n","Training mini-batch number 477000\n","Training mini-batch number 478000\n","Training mini-batch number 479000\n","Training mini-batch number 480000\n","Training mini-batch number 481000\n","Training mini-batch number 482000\n","Training mini-batch number 483000\n","Training mini-batch number 484000\n","Training mini-batch number 485000\n","Training mini-batch number 486000\n","Training mini-batch number 487000\n","Training mini-batch number 488000\n","Training mini-batch number 489000\n","Training mini-batch number 490000\n","Training mini-batch number 491000\n","Training mini-batch number 492000\n","Training mini-batch number 493000\n","Training mini-batch number 494000\n","Training mini-batch number 495000\n","Training mini-batch number 496000\n","Training mini-batch number 497000\n","Training mini-batch number 498000\n","Training mini-batch number 499000\n","Epoch 19: validation accuracy 99.51%\n","Finished training network.\n","Best validation accuracy of 99.61% obtained at iteration 474999\n","Corresponding test accuracy of 99.58%\n"],"name":"stdout"}]}]}